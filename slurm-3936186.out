==========================================
SLURM_JOB_ID = 3936186
SLURM_JOB_NODELIST = node047
==========================================
2025-03-17 00:32:19,322 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.47:45067'
2025-03-17 00:32:19,332 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.47:35265'
2025-03-17 00:32:19,338 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.47:35269'
2025-03-17 00:32:19,346 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.47:40365'
2025-03-17 00:32:21,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-v673kde2', purging
2025-03-17 00:32:21,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-z4z_jkv8', purging
2025-03-17 00:32:21,564 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-6x39d6qw', purging
2025-03-17 00:32:21,565 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-sij1n1d8', purging
2025-03-17 00:32:21,596 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.47:34833
2025-03-17 00:32:21,597 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.47:34833
2025-03-17 00:32:21,597 - distributed.worker - INFO -           Worker name:           SLURMCluster-3-2
2025-03-17 00:32:21,597 - distributed.worker - INFO -          dashboard at:          10.224.1.47:33141
2025-03-17 00:32:21,597 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:36029
2025-03-17 00:32:21,597 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:21,598 - distributed.worker - INFO -               Threads:                          1
2025-03-17 00:32:21,598 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-17 00:32:21,598 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-7cbxbaaq
2025-03-17 00:32:21,598 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:21,605 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.47:45199
2025-03-17 00:32:21,605 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.47:45199
2025-03-17 00:32:21,605 - distributed.worker - INFO -           Worker name:           SLURMCluster-3-0
2025-03-17 00:32:21,606 - distributed.worker - INFO -          dashboard at:          10.224.1.47:46055
2025-03-17 00:32:21,606 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:36029
2025-03-17 00:32:21,606 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:21,606 - distributed.worker - INFO -               Threads:                          1
2025-03-17 00:32:21,606 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-17 00:32:21,607 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-zvfso0w4
2025-03-17 00:32:21,607 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:21,621 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.47:43029
2025-03-17 00:32:21,622 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.47:43029
2025-03-17 00:32:21,622 - distributed.worker - INFO -           Worker name:           SLURMCluster-3-3
2025-03-17 00:32:21,622 - distributed.worker - INFO -          dashboard at:          10.224.1.47:36485
2025-03-17 00:32:21,622 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:36029
2025-03-17 00:32:21,622 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:21,623 - distributed.worker - INFO -               Threads:                          1
2025-03-17 00:32:21,623 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-17 00:32:21,623 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-dd00ptuh
2025-03-17 00:32:21,623 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:21,665 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.47:42003
2025-03-17 00:32:21,666 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.47:42003
2025-03-17 00:32:21,666 - distributed.worker - INFO -           Worker name:           SLURMCluster-3-1
2025-03-17 00:32:21,666 - distributed.worker - INFO -          dashboard at:          10.224.1.47:34181
2025-03-17 00:32:21,666 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:36029
2025-03-17 00:32:21,666 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:21,667 - distributed.worker - INFO -               Threads:                          1
2025-03-17 00:32:21,667 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-17 00:32:21,667 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-i4bc0uos
2025-03-17 00:32:21,667 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:22,673 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-17 00:32:22,675 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:36029
2025-03-17 00:32:22,674 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-17 00:32:22,675 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:22,676 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:36029
2025-03-17 00:32:22,676 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:36029
2025-03-17 00:32:22,677 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:22,678 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:36029
2025-03-17 00:32:22,675 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-17 00:32:22,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-17 00:32:22,681 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:36029
2025-03-17 00:32:22,681 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:22,682 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:36029
2025-03-17 00:32:22,683 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:36029
2025-03-17 00:32:22,684 - distributed.worker - INFO - -------------------------------------------------
2025-03-17 00:32:22,686 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:36029
slurmstepd-node047: error: *** JOB 3936186 ON node047 CANCELLED AT 2025-03-17T00:40:56 ***
