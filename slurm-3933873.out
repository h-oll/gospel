==========================================
SLURM_JOB_ID = 3933873
SLURM_JOB_NODELIST = node023
==========================================
2025-03-16 14:45:36,541 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.23:46315'
2025-03-16 14:45:36,546 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.23:39631'
2025-03-16 14:45:36,548 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.23:32903'
2025-03-16 14:45:36,553 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.23:45699'
2025-03-16 14:45:37,681 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.23:40845
2025-03-16 14:45:37,681 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.23:40845
2025-03-16 14:45:37,681 - distributed.worker - INFO -           Worker name:          SLURMCluster-10-0
2025-03-16 14:45:37,681 - distributed.worker - INFO -          dashboard at:          10.224.1.23:42531
2025-03-16 14:45:37,681 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:43991
2025-03-16 14:45:37,681 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:37,681 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:45:37,682 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:45:37,682 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-g40kysof
2025-03-16 14:45:37,682 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:37,733 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.23:36417
2025-03-16 14:45:37,734 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.23:36417
2025-03-16 14:45:37,734 - distributed.worker - INFO -           Worker name:          SLURMCluster-10-2
2025-03-16 14:45:37,734 - distributed.worker - INFO -          dashboard at:          10.224.1.23:44375
2025-03-16 14:45:37,734 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:43991
2025-03-16 14:45:37,734 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:37,734 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:45:37,734 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:45:37,734 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-6tzac2gb
2025-03-16 14:45:37,734 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:37,853 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.23:35625
2025-03-16 14:45:37,853 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.23:35625
2025-03-16 14:45:37,853 - distributed.worker - INFO -           Worker name:          SLURMCluster-10-1
2025-03-16 14:45:37,853 - distributed.worker - INFO -          dashboard at:          10.224.1.23:40761
2025-03-16 14:45:37,853 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:43991
2025-03-16 14:45:37,853 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:37,854 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:45:37,854 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:45:37,854 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-045gjjg3
2025-03-16 14:45:37,854 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:37,950 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.23:44717
2025-03-16 14:45:37,950 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.23:44717
2025-03-16 14:45:37,951 - distributed.worker - INFO -           Worker name:          SLURMCluster-10-3
2025-03-16 14:45:37,951 - distributed.worker - INFO -          dashboard at:          10.224.1.23:42341
2025-03-16 14:45:37,951 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:43991
2025-03-16 14:45:37,951 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:37,951 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:45:37,951 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:45:37,951 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-xubalfa_
2025-03-16 14:45:37,951 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:38,125 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:45:38,126 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:43991
2025-03-16 14:45:38,126 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:38,127 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:43991
2025-03-16 14:45:38,193 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:45:38,194 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:43991
2025-03-16 14:45:38,194 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:38,195 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:43991
2025-03-16 14:45:38,265 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:45:38,266 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:43991
2025-03-16 14:45:38,266 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:38,267 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:43991
2025-03-16 14:45:38,272 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:45:38,273 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:43991
2025-03-16 14:45:38,273 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:45:38,273 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:43991
slurmstepd-node023: error: *** JOB 3933873 ON node023 CANCELLED AT 2025-03-16T14:45:47 ***
