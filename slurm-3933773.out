==========================================
SLURM_JOB_ID = 3933773
SLURM_JOB_NODELIST = node023
==========================================
2025-03-16 14:21:28,421 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.23:34945'
2025-03-16 14:21:28,426 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.23:39027'
2025-03-16 14:21:28,429 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.23:38187'
2025-03-16 14:21:28,433 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.23:33355'
2025-03-16 14:21:29,534 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.23:43707
2025-03-16 14:21:29,534 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.23:38433
2025-03-16 14:21:29,534 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.23:43707
2025-03-16 14:21:29,535 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.23:38433
2025-03-16 14:21:29,535 - distributed.worker - INFO -           Worker name:          SLURMCluster-24-1
2025-03-16 14:21:29,535 - distributed.worker - INFO -           Worker name:          SLURMCluster-24-0
2025-03-16 14:21:29,535 - distributed.worker - INFO -          dashboard at:          10.224.1.23:39933
2025-03-16 14:21:29,535 - distributed.worker - INFO -          dashboard at:          10.224.1.23:41145
2025-03-16 14:21:29,535 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:41779
2025-03-16 14:21:29,535 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:41779
2025-03-16 14:21:29,535 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,535 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,535 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:21:29,535 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:21:29,535 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:21:29,535 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:21:29,535 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-0_clssh8
2025-03-16 14:21:29,535 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-m9gc6hha
2025-03-16 14:21:29,535 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,535 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,884 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.23:36913
2025-03-16 14:21:29,885 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.23:36913
2025-03-16 14:21:29,885 - distributed.worker - INFO -           Worker name:          SLURMCluster-24-2
2025-03-16 14:21:29,885 - distributed.worker - INFO -          dashboard at:          10.224.1.23:35763
2025-03-16 14:21:29,885 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:41779
2025-03-16 14:21:29,885 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,885 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:21:29,885 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:21:29,885 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-q3aoaov7
2025-03-16 14:21:29,886 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,910 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.23:41641
2025-03-16 14:21:29,910 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.23:41641
2025-03-16 14:21:29,910 - distributed.worker - INFO -           Worker name:          SLURMCluster-24-3
2025-03-16 14:21:29,910 - distributed.worker - INFO -          dashboard at:          10.224.1.23:39109
2025-03-16 14:21:29,911 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:41779
2025-03-16 14:21:29,911 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,911 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:21:29,911 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:21:29,911 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-p6d3l71r
2025-03-16 14:21:29,911 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:21:29,922 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:41779
2025-03-16 14:21:29,922 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,923 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:41779
2025-03-16 14:21:29,926 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:21:29,927 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:41779
2025-03-16 14:21:29,927 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:29,927 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:41779
2025-03-16 14:21:30,193 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:21:30,194 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:41779
2025-03-16 14:21:30,194 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:30,195 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:41779
2025-03-16 14:21:30,228 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:21:30,229 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:41779
2025-03-16 14:21:30,229 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:21:30,229 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:41779
slurmstepd-node023: error: *** JOB 3933773 ON node023 CANCELLED AT 2025-03-16T14:21:42 ***
