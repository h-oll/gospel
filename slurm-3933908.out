==========================================
SLURM_JOB_ID = 3933908
SLURM_JOB_NODELIST = node047
==========================================
2025-03-16 14:47:04,053 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.47:34977'
2025-03-16 14:47:04,062 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.47:43637'
2025-03-16 14:47:04,068 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.47:38795'
2025-03-16 14:47:04,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.47:34387'
2025-03-16 14:47:06,338 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.47:39111
2025-03-16 14:47:06,338 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.47:40969
2025-03-16 14:47:06,339 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.47:39111
2025-03-16 14:47:06,339 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.47:40969
2025-03-16 14:47:06,339 - distributed.worker - INFO -           Worker name:          SLURMCluster-11-2
2025-03-16 14:47:06,339 - distributed.worker - INFO -           Worker name:          SLURMCluster-11-1
2025-03-16 14:47:06,339 - distributed.worker - INFO -          dashboard at:          10.224.1.47:43443
2025-03-16 14:47:06,339 - distributed.worker - INFO -          dashboard at:          10.224.1.47:43763
2025-03-16 14:47:06,340 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:34973
2025-03-16 14:47:06,340 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:34973
2025-03-16 14:47:06,340 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:06,340 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:06,340 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:47:06,340 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:47:06,340 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:47:06,340 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:47:06,341 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-csmgp1xs
2025-03-16 14:47:06,341 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-8indp6j3
2025-03-16 14:47:06,341 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:06,341 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:06,357 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.47:43985
2025-03-16 14:47:06,358 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.47:43985
2025-03-16 14:47:06,358 - distributed.worker - INFO -           Worker name:          SLURMCluster-11-0
2025-03-16 14:47:06,358 - distributed.worker - INFO -          dashboard at:          10.224.1.47:46399
2025-03-16 14:47:06,358 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:34973
2025-03-16 14:47:06,359 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:06,359 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:47:06,359 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:47:06,359 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-kpt1g45f
2025-03-16 14:47:06,360 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:06,389 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.47:37061
2025-03-16 14:47:06,389 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.47:37061
2025-03-16 14:47:06,390 - distributed.worker - INFO -           Worker name:          SLURMCluster-11-3
2025-03-16 14:47:06,390 - distributed.worker - INFO -          dashboard at:          10.224.1.47:44401
2025-03-16 14:47:06,390 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:34973
2025-03-16 14:47:06,390 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:06,390 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:47:06,391 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:47:06,391 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-hvrak9p7
2025-03-16 14:47:06,391 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:07,226 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:47:07,227 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:34973
2025-03-16 14:47:07,228 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:07,229 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:34973
2025-03-16 14:47:07,231 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:47:07,232 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:47:07,233 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:34973
2025-03-16 14:47:07,233 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:34973
2025-03-16 14:47:07,233 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:07,233 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:07,234 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:34973
2025-03-16 14:47:07,235 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:34973
2025-03-16 14:47:07,265 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:47:07,266 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:34973
2025-03-16 14:47:07,266 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:47:07,268 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:34973
slurmstepd-node047: error: *** JOB 3933908 ON node047 CANCELLED AT 2025-03-16T14:47:19 ***
