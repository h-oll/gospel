==========================================
SLURM_JOB_ID = 3933824
SLURM_JOB_NODELIST = node024
==========================================
2025-03-16 14:43:43,619 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.24:42149'
2025-03-16 14:43:43,625 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.24:44967'
2025-03-16 14:43:43,629 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.24:38735'
2025-03-16 14:43:43,634 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.224.1.24:35741'
2025-03-16 14:43:44,832 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-jgre1v8u', purging
2025-03-16 14:43:44,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-ptb5gaod', purging
2025-03-16 14:43:44,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-k_psues5', purging
2025-03-16 14:43:44,833 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-cme6itsj', purging
2025-03-16 14:43:44,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-rz___ahu', purging
2025-03-16 14:43:44,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-m6pz1_wf', purging
2025-03-16 14:43:44,834 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-63i6qgb6', purging
2025-03-16 14:43:44,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-jsxdo7w4', purging
2025-03-16 14:43:44,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-rt1mdnf5', purging
2025-03-16 14:43:44,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-2wn2qt7o', purging
2025-03-16 14:43:44,835 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-eictaqoe', purging
2025-03-16 14:43:44,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-ntk1fcat', purging
2025-03-16 14:43:44,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-t7h68odm', purging
2025-03-16 14:43:44,836 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-d27k1k4b', purging
2025-03-16 14:43:44,837 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-e7y2ku61', purging
2025-03-16 14:43:44,837 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space-672848/worker-9h77f22l', purging
2025-03-16 14:43:44,850 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.24:40721
2025-03-16 14:43:44,850 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.24:40721
2025-03-16 14:43:44,850 - distributed.worker - INFO -           Worker name:          SLURMCluster-22-0
2025-03-16 14:43:44,851 - distributed.worker - INFO -          dashboard at:          10.224.1.24:43397
2025-03-16 14:43:44,851 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:45905
2025-03-16 14:43:44,851 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:44,851 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:43:44,851 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:43:44,851 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-01t3g4pt
2025-03-16 14:43:44,851 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:44,955 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.24:46549
2025-03-16 14:43:44,955 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.24:46549
2025-03-16 14:43:44,955 - distributed.worker - INFO -           Worker name:          SLURMCluster-22-1
2025-03-16 14:43:44,955 - distributed.worker - INFO -          dashboard at:          10.224.1.24:39479
2025-03-16 14:43:44,955 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:45905
2025-03-16 14:43:44,956 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:44,956 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:43:44,956 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:43:44,956 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-z3rybr7r
2025-03-16 14:43:44,956 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:44,957 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.24:35339
2025-03-16 14:43:44,958 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.24:35339
2025-03-16 14:43:44,958 - distributed.worker - INFO -           Worker name:          SLURMCluster-22-2
2025-03-16 14:43:44,958 - distributed.worker - INFO -          dashboard at:          10.224.1.24:46597
2025-03-16 14:43:44,958 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:45905
2025-03-16 14:43:44,958 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:44,958 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:43:44,959 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:43:44,959 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-qh46xvoi
2025-03-16 14:43:44,959 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:45,051 - distributed.worker - INFO -       Start worker at:    tcp://10.224.1.24:43661
2025-03-16 14:43:45,052 - distributed.worker - INFO -          Listening to:    tcp://10.224.1.24:43661
2025-03-16 14:43:45,052 - distributed.worker - INFO -           Worker name:          SLURMCluster-22-3
2025-03-16 14:43:45,052 - distributed.worker - INFO -          dashboard at:          10.224.1.24:46799
2025-03-16 14:43:45,052 - distributed.worker - INFO - Waiting to connect to:   tcp://128.93.170.2:45905
2025-03-16 14:43:45,052 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:45,052 - distributed.worker - INFO -               Threads:                          1
2025-03-16 14:43:45,052 - distributed.worker - INFO -                Memory:                   0.93 GiB
2025-03-16 14:43:45,052 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space-672848/worker-bpnd16hb
2025-03-16 14:43:45,053 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:45,389 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:43:45,389 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:45905
2025-03-16 14:43:45,389 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:45,390 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:45905
2025-03-16 14:43:45,391 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:43:45,392 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:45905
2025-03-16 14:43:45,392 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:45,393 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:45905
2025-03-16 14:43:45,395 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:43:45,396 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:45905
2025-03-16 14:43:45,396 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:45,397 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:45905
2025-03-16 14:43:45,447 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-16 14:43:45,448 - distributed.worker - INFO -         Registered to:   tcp://128.93.170.2:45905
2025-03-16 14:43:45,448 - distributed.worker - INFO - -------------------------------------------------
2025-03-16 14:43:45,448 - distributed.core - INFO - Starting established connection to tcp://128.93.170.2:45905
slurmstepd-node024: error: *** JOB 3933824 ON node024 CANCELLED AT 2025-03-16T14:43:54 ***
